{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b513652-cd12-402c-a9f1-d3cb7c7a19f9",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89b8c9c7-de0c-4714-8b18-aeeea80df770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, infer_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4aad3f61-11de-43a3-94ca-1cc167115de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6d0e353868427da8199f65ae90ccf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44b7bea9-8f8b-4102-a904-5c27a83a6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52d44a-3931-4604-b90a-a7c869518edb",
   "metadata": {},
   "source": [
    "## Verifying cuda is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0919cc21-4692-498a-9bef-f6a815ff2036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21212fed-4adc-40f0-b858-1a3ebb60cf0c",
   "metadata": {},
   "source": [
    "# setting to use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "21fdfff0-055d-4805-8b66-e1ff53eb267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = infer_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d0c206dd-c972-4252-830d-80ea9f1385b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline(\"text-generation\", model=\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca88eb-bed8-4c7e-bb8b-091847bf5d01",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "634a53ea-f4c1-4d50-b938-567d1a7043e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The secret to baking a good cake is \\xa0to make sure you don\\'t bake too hard or too thin. When you bake a cake, there are two different types of cake: the \"regular\" cake you get for Christmas, and the \"cake\" you get that same year. The regular cake is a large, round cake that you can bake in the oven for several hours. The cake you get for Christmas is a soft, round cake that you can bake for hours. The cake you get for Christmas is a sweet cake that you can bake in the oven for hours. The cake you get for Christmas is a cake that will be filled on the inside with a few drops of sugar. The cake you get for Christmas is a cake that will be filled with a few drops of sugar.\\nWhen you bake a cake, it is important to use an oven that is as hot as possible (if it is not, it will not bake very well). When baking a cake, it is important to use an oven that is as hot as possible (if it is not, it will not bake very well). The baking process is so simple that it is easy to understand. It is the best way to get the most out of a cake.\\nIf you want to get a cake that is not a cake,'}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"The secret to baking a good cake is \", max_length=50, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbe48332-dbdd-4228-8509-9da0680479e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'What planets are in the solar system? Find out how your telescope measures Earth, Moon, Mars, Pluto, and even Pluto!\\n\\nThe Milky Way galaxy is comprised of 4.7 billion light-years (4.7 billion kilometers), one-fifth of the Sun. This giant bulge of the Milky Way galaxy is the largest in the Milky Way System. Astronomers believe the galaxy sits over the Milky'}]\n"
     ]
    }
   ],
   "source": [
    "output = pipeline(\"What planets are in the solar system?\", temperature=1, do_sample=True, max_new_tokens=75)   \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7f7b01e7-378e-402d-9af4-dd5202dd8f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"What planets are in the solar system?\\n\\nThe moon is a pretty big mystery. But there are plenty of planets that are quite massive, and there are plenty of planets that are quite massive.\\n\\nHow do you know that?\\n\\nBecause they're so massive, and they're so close to our sun, they're very close to our sun. So, there are planets that are quite massive,\"}]\n"
     ]
    }
   ],
   "source": [
    "output = pipe(\"What planets are in the solar system?\", temperature=.7, do_sample=True, max_new_tokens=75)   \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "701fb51f-75fe-4744-b873-b82b6820fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'What planets are in the solar system?\\n\\nThe most common question I get is \"What planets are in the solar system?\" The answer is \"Mars.\" The answer is \"Earth.\" The answer is \"Mars.\" The answer is \"Earth.\" The answer is \"Mars.\" The answer is \"Earth.\" The answer is \"Mars.\" The answer is \"Earth.\" The answer is \"Mars.\" The answer is'}]\n"
     ]
    }
   ],
   "source": [
    "output = pipe(\"What planets are in the solar system?\", temperature=.2, do_sample=True, max_new_tokens=75)   \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037409f-2e8a-4c8f-9631-300b2f5fd73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrainedllm",
   "language": "python",
   "name": ".envgenai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
